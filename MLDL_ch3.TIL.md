# Ch.3 íšŒê·€ ì•Œê³ ë¦¬ì¦˜ê³¼ ëª¨ë¸ ê·œì œ

íšŒê·€ ì•Œê³ ë¦¬ì¦˜ê³¼ ëª¨ë¸ ê·œì œ

# 3-1. k-ìµœê·¼ì ‘ ì´ì›ƒ íšŒê·€

í•œë¹› ë§ˆì¼“ì€ ì—¬ë¦„ ë†ì–´ì² ì„ ë§ì•„ ë†ì–´ë¥¼ **ë¬´ê²Œ ë‹¨ìœ„ë¡œ íŒë§¤**í•˜ê¸°ë¡œ í•œë‹¤.

ê¸°ì¡´ì—ëŠ” ë§ˆë¦¬ë‹¹ ê°€ê²©ìœ¼ë¡œ íŒë§¤í–ˆì§€ë§Œ, ê³ ê°ë“¤ì´ ê¸°ëŒ€ë³´ë‹¤ ì‘ì€ ë†ì–´ë¥¼ ë°›ì•˜ë‹¤ê³  í•­ì˜í•˜ëŠ” ì¼ì´ ìƒê²¨ ë¬´ê²Œ ê¸°ì¤€ì´ ë” í•©ë¦¬ì ì´ë¼ê³  íŒë‹¨í•œ ê²ƒì´ë‹¤.

ê·¸ëŸ°ë° ê³µê¸‰ì²˜ì—ì„œ **ë†ì–´ ë¬´ê²Œë¥¼ ì˜ëª» ì¸¡ì •**í•´ë³´ë‚´ëŠ” ë°”ëŒì— ë¬¸ì œê°€ ìƒê¸´ë‹¤.

ë‹¤í–‰íˆ ê¸¸ì´, ë†’ì´, ë‘ê»˜ ê°™ì€ ë‹¤ë¥¸ ë°ì´í„°ëŠ” ì •í™•í•˜ê²Œ ì¸¡ì •ë˜ì–´ ìˆì–´ ì´ë¥¼ í™œìš©í•´ **ë¬´ê²Œë¥¼ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸**ì„ ë§Œë“¤ì–´ë³´ê¸°ë¡œ í•œë‹¤.

## k-ìµœê·¼ì ‘ ì´ì›ƒ íšŒê·€ (k-NN Regression)

- **k-NN ë¶„ë¥˜**ëŠ” ì£¼ë³€ì— ê°€ê¹Œìš´ ìƒ˜í”Œ kê°œë¥¼ ì°¾ì•„ **ê°€ì¥ ë§ì€ í´ë˜ìŠ¤**ë¥¼ ì •ë‹µìœ¼ë¡œ ì„ íƒ
- **k-NN íšŒê·€**ëŠ” ì£¼ë³€ì˜ ìƒ˜í”Œ kê°œì˜ ìˆ˜ì¹˜(target ê°’)ë¥¼ í‰ê·  ë‚´ì„œ ì˜ˆì¸¡ê°’ìœ¼ë¡œ ì‚¬ìš©

ex) ê°€ê¹Œìš´ ì´ì›ƒ 3ê°œì˜ ë¬´ê²Œê°€ 100g, 80g, 60gì´ë¼ë©´, ì˜ˆì¸¡ê°’ì€ í‰ê· ì¸ **80g**

```jsx
##ë°ì´í„°ì¤€ë¹„
import numpy as np
perch_length = np.array(
[ 8.4, 13.7, 15.0, 16.2, 17.4, 18.0, 18.7, 19.0, 19.6, 20.0,
21.0, 21.0, 21.0, 21.3, 22.0, 22.0, 22.0, 22.0, 22.0, 22.5,
22.5, 22.7, 23.0, 23.5, 24.0, 24.0, 24.6, 25.0, 25.6, 26.5,
27.3, 27.5, 27.5, 27.5, 28.0, 28.7, 30.0, 32.8, 34.5, 35.0,
36.5, 36.0, 37.0, 37.0, 39.0, 39.0, 39.0, 40.0, 40.0, 40.0,
40.0, 42.0, 43.0, 43.0, 43.5, 44.0])
perch_weight = np.array(
[5.9, 32.0, 40.0, 51.5, 70.0, 100.0, 78.0, 80.0, 85.0, 85.0,
110.0, 115.0, 125.0, 130.0, 120.0, 120.0, 130.0, 135.0, 110.0,
130.0, 150.0, 145.0, 150.0, 170.0, 225.0, 145.0, 188.0, 180.0,
197.0, 218.0, 300.0, 260.0, 265.0, 250.0, 250.0, 300.0, 320.0,
514.0, 556.0, 840.0, 685.0, 700.0, 700.0, 690.0, 900.0, 650.0,
820.0, 850.0, 900.0, 1015.0, 820.0, 1100.0, 1000.0, 1100.0,
1000.0, 1000.0]
)
```

- ê¸¸ì´ì™€ ë¬´ê²Œì˜ ì‚°ì ë„

```jsx
import matplotlib.pyplot as plt
plt.scatter(perch_length, perch_weight)
plt.xlabel('length')
plt.ylabel('weight')
plt.show()
```

![image.png](image.png)

-ë‹¹ì—°í•˜ê²Œë„ ë†ì–´ì˜ ê¸¸ì´ê°€ ëŠ˜ì–´ë‚ ìˆ˜ë¡ ë¬´ê²Œë„ ëŠ˜ì–´ë‚¨

```jsx
from sklearn.model_selection import train_test_split
train_input, test_input, train_target, test_target = train_test_split(
perch_length, perch_weight, random_state=42
```

-ì‚¬ì´í‚·ëŸ°ì˜ train_test_split () í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ í›ˆë ¨ ì„¸íŠ¸ì™€ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ë‚˜ëˆ”

```jsx
test_array = np.array([1,2,3,4])
print(test_array.shape)
test_array = test_array.reshape(2, 2)
print(test_array.shape)
```

```jsx
train_input = train_input.reshape(-1, 1)
test_input = test_input.reshape(-1, 1)
print(train_input.shape, test_input.shape)
```

- ì‚¬ì´í‚·ëŸ°ì— ì‚¬ìš©í•  í›ˆë ¨ ì„¸íŠ¸ëŠ” 2ì°¨ì› ë°°ì—´ì´ì–´ì•¼ í•¨ â†’ ìˆ˜ë™ìœ¼ë¡œ ë³€ê²½
- reshape (-1, 1)ê³¼ ê°™ì´ ì‚¬ìš©í•˜ë©´ ë°°ì—´ì˜ ì „ì²´ ì›ì†Œ ê°œìˆ˜ë¥¼ ë§¤ë²ˆ ì™¸ìš°ì§€ ì•Šì•„ë„ ë˜ë¯€ë¡œ í¸ë¦¬í•¨

### ëª¨ë¸ í›ˆë ¨ ë° ê²°ì •ê³„ìˆ˜ RÂ²

- KNeighbors Regressor: ì‚¬ì´í‚·ëŸ°ì—ì„œ k-ìµœê·¼ì ‘ ì´ì›ƒ íšŒê·€ ì•Œê³ ë¦¬ì¦˜ì„ êµ¬í˜„í•œ í´ë˜ìŠ¤

```jsx
from sklearn.neighbors import KNeighborsRegressor
knr = KNeighborsRegressor()
#k-ìµœê·¼ì ‘ ì´ì›ƒ íšŒê·€ ëª¨ë¸ì„ í›ˆë ¨í•©ë‹ˆë‹¤
knr.fit(train_input, train_target)
```

```jsx
 print(knr.score(test_input, test_target))
```

0.9928094061010639ì˜ ì ìˆ˜ê°’: **ê²°ì •ê³„ìˆ˜ RÂ²**

- ëª¨ë¸ì´ íƒ€ê¹ƒê°’ì˜ ë³€ë™ì„±ì„ ì–¼ë§ˆë‚˜ ì˜ ì„¤ëª…í•˜ëŠ”ì§€ ë‚˜íƒ€ëƒ„
- 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì˜ˆì¸¡ì´ ì˜ ëœê²ƒ

### í‰ê·  ì ˆëŒ“ê°’ ì˜¤ì°¨ (MAE, Mean Absolute Error)

- ê° ìƒ˜í”Œì—ì„œ ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì˜ ì°¨ì´(ì ˆëŒ“ê°’)ë¥¼ ëª¨ë‘ ë”í•œ ë’¤, ê·¸ í‰ê· ì„ êµ¬í•œ ê°’

```jsx
from sklearn.metrics import mean_absolute_error
#í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì— ëŒ€í•œ ì˜ˆì¸¡ì„ ë§Œë“­ë‹ˆë‹¤.
test_prediction = knr.predict(test_input)
#í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì— ëŒ€í•œ í‰ê·  ì ˆëŒ“ê°’ ì˜¤ì°¨ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤
mae = mean_absolute_error(test_target, test_prediction)
print(mae)
```

19.157142857142862: ì˜ˆì¸¡ì´ í‰ê· ì ìœ¼ë¡œ 19g ì •ë„ íƒ€ê¹ƒê°’ê³¼ ë‹¤ë¥´ë‹¤ëŠ” ê²ƒ

### ê³¼ëŒ€ì í•© vs ê³¼ì†Œì í•©

```jsx
print(knr.score(train_input, train_target))
```

í›ˆë ¨ ì„¸íŠ¸ë³´ë‹¤ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì˜ ì ìˆ˜ê°€ ë†’ìœ¼ë‹ˆ **ê³¼ì†Œì í•©**

- **ê³¼ì†Œì í•©**

       í›ˆë ¨ ì„¸íŠ¸ë³´ë‹¤ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì˜ ì ìˆ˜ê°€ ë†’ê±°ë‚˜ ë‘ ì ìˆ˜ê°€ ëª¨ë‘ ë„ˆë¬´ ë‚®ì€ ê²½ìš°

      ëª¨ë¸ì´ ë„ˆë¬´ ë‹¨ìˆœí•˜ì—¬ í›ˆë ¨ ì„¸íŠ¸ì— ì ì ˆíˆ í›ˆë ¨ë˜ì§€ ì•Šì€ ê²½ìš°

- **ê³¼ëŒ€ì í•©**

       í›ˆë ¨ ì„¸íŠ¸ì—ì„œ ì ìˆ˜ê°€ êµ‰ì¥íˆ ì¢‹ì•˜ëŠ”ë° í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œëŠ” ì ìˆ˜ê°€ êµ‰ì¥íˆ ë‚˜ìœ ê²½ìš°

       í›ˆë ¨ ì„¸íŠ¸ì—ë§Œ ì˜ ë§ëŠ” ëª¨ë¸ì´ë¼ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì™€ ë‚˜ì¤‘ì— ì‹¤ì „ì— íˆ¬ì…í•˜ì—¬ ìƒˆë¡œìš´ ìƒ˜í”Œì— ëŒ€í•œ ì˜ˆì¸¡ì„ 

       ë§Œë“¤ê¸° ë¶€ì í•©í•œ ê²½ìš°

### ê³¼ì†Œì í•© í•´ê²°

ëª¨ë¸ì„ ì¡°ê¸ˆ ë” ë³µì¡í•˜ê²Œ ë§Œë“¤ì–´ ê³¼ì†Œì í•© í•´ê²°

- k-ìµœê·¼ì ‘ ì´ì›ƒ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ëª¨ë¸ì„ ë” ë³µì¡í•˜ê²Œ ë§Œë“œëŠ” ë°©ë²•ì€ ì´ì›ƒì˜ ê°œìˆ˜ kë¥¼ ì¤„ì´ëŠ” ê²ƒ

```jsx
#ì´ì›ƒì˜ ê°œìˆ˜ë¥¼ 3ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
knr.n_neighbors = 3
#ëª¨ë¸ì„ ë‹¤ì‹œ í›ˆë ¨í•©ë‹ˆë‹¤.
knr.fit(train_input, train_target)
print(knr.score(train_input, train_target))
```

k ê°’ì„ ì¤„ì˜€ë”ë‹ˆ í›ˆë ¨ ì„¸íŠ¸ì˜ **RÂ²** ì ìˆ˜ê°€ ë†’ì•„ì§

```jsx
print(knr.score(test_input, test_target))
```

- í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì˜ ì ìˆ˜ëŠ” í›ˆë ¨ ì„¸íŠ¸ë³´ë‹¤ ë‚®ì•„ì¡Œìœ¼ë¯€ë¡œ ê³¼ì†Œì í•© ë¬¸ì œë¥¼ í•´ê²°í•¨
- ë‘ ì ìˆ˜ì˜ ì°¨ì´ê°€ í¬ì§€ ì•Šìœ¼ë¯€ë¡œ ì´ ëª¨ë¸ì´ ê³¼ëŒ€ì í•©ë„ ì•„ë‹˜

# 3-2. ì„ í˜• íšŒê·€

## k-ìµœê·¼ì ‘ ì´ì›ƒ íšŒê·€ì˜ í•œê³„

í›ˆë ¨ ë°ì´í„° ë²”ìœ„ ë°–ì˜ ì˜ˆì¸¡ì—ì„œ ë¬¸ì œê°€ ìƒê¹€

- `perch_length` ë°ì´í„°ë¥¼ ë³´ë©´ ê°€ì¥ ê¸´ ë†ì–´ê°€ 44.0cmì— ë¶ˆê³¼
- ëª¨ë¸ì´ ë³¸ ì  ì—†ëŠ” êµ¬ê°„ì—ì„œ ì˜ˆì¸¡ì„ í•˜ê²Œ ëœ ê²ƒ
- ê°€ì¥ ê°€ê¹Œìš´ ìƒ˜í”Œë„ 40cm ê·¼ì²˜ì— ìˆì–´ ìµœê·¼ì ‘ ë°©ë²•ì— í•œê³„ê°€ ìƒê¹€

```jsx
print(knr.predict([[50]]))
```

ê¸¸ì´ê°€ 50cmì¸ ë†ì–´ì˜ ë¬´ê²Œë¥¼ ì˜ˆì¸¡í–ˆì„ ë•Œ ì‹¤ì œë³´ë‹¤ í›¨ì”¬ ì‘ì€ ê°’ì´ ë‚˜ì˜´

```jsx
import matplotlib.pyplot as plt
#50cm ë†ì–´ì˜ ì´ì›ƒì„ êµ¬í•©ë‹ˆë‹¤
distances, indexes = knr.kneighbors([[50]])
#í›ˆë ¨ ì„¸íŠ¸ì˜ ì‚°ì ë„ë¥¼ ê·¸ë¦½ë‹ˆë‹¤.
plt.scatter(train_input, train_target)
#í›ˆë ¨ ì„¸íŠ¸ ì¤‘ì—ì„œ ì´ì›ƒ ìƒ˜í”Œë§Œ ë‹¤ì‹œ ê·¸ë¦½ë‹ˆë‹¤.
plt.scatter(train_input[indexes], train_target[indexes], marker='D')
#50cm ë†ì–´ ë°ì´í„°
plt.scatter(50, 1033, marker='^')
plt.xlabel('length')
plt.ylabel('weight')
plt.show()
```

![image.png](image%201.png)

- í›ˆë ¨ ì„¸íŠ¸ì™€ 50cm ë†ì–´ ê·¸ë¦¬ê³  ì´ ë†ì–´ì˜ ìµœê·¼ì ‘ ì´ì›ƒì˜ ì‚°ì ë„
- k-ìµœê·¼ì ‘ ì´ì›ƒ íšŒê·€ëŠ” ê°€ì¥ ê°€ê¹Œìš´ ìƒ˜í”Œì„ ì°¾ì•„ íƒ€ê¹ƒì„ í‰ê· 
- ë”°ë¼ì„œ ìƒˆë¡œìš´ ìƒ˜í”Œì´ í›ˆë ¨ ì„¸íŠ¸ì˜ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ë©´ ì—‰ëš±í•œ ê°’ì„ ì˜ˆì¸¡í•  ìˆ˜ ìˆìŒ
ì˜ˆë¥¼ ë“¤ì–´ ê¸¸ì´ê°€ 100cmì¸ ë†ì–´ë„ ì—¬ì „íˆ 1,033gìœ¼ë¡œ ì˜ˆì¸¡
- â†’ ë‹¤ë¥¸ ì•Œê³ ë¦¬ì¦˜ í•„ìš”!

## ì„ í˜• íšŒê·€

- íŠ¹ì„±ì´ í•˜ë‚˜ì¸ ê²½ìš° ì–´ë–¤ ì§ì„ ì„ í•™ìŠµí•˜ëŠ” ì•Œê³ ë¦¬ì¦˜
- ë¹„êµì  ê°„ë‹¨í•˜ê³  ì„±ëŠ¥ì´ ë›°ì–´ë‚¨

```jsx
from sklearn.linear_model import LinearRegression
lr = LinearRegression()
#ì„ í˜• íšŒê·€ ëª¨ë¸ì„ í›ˆë ¨í•©ë‹ˆë‹¤
lr.fit(train_input, train_target)
#50cm ë†ì–´ì— ëŒ€í•´ ì˜ˆì¸¡í•©ë‹ˆë‹¤
print(lr.predict([[50]]))
```

k-ìµœê·¼ì ‘ ì´ì›ƒ íšŒê·€ë¥¼ ì‚¬ìš©í–ˆì„ ë•Œì™€ ë‹¬ë¦¬ ì„ í˜• íšŒê·€ëŠ” 50cm ë†ì–´ì˜ ë¬´ê²Œë¥¼ ì•„ì£¼ ë†’ê²Œ ì˜ˆì¸¡

![KakaoTalk_20250708_094145847.png](KakaoTalk_20250708_094145847.png)

xë¥¼ ë†ì–´ì˜ ê¸¸ì´, ë¥¼ ë†ì–´ì˜ ë¬´ê²Œë¡œ ì„ í˜• íšŒê·€ê°€ í•™ìŠµí•œ ì§ì„ 

```jsx
 print(lr.coef, lr.intercept_)
```

ê¸°ìš¸ê¸°: 39.01714496         ì ˆí¸: -709.0186449535477

```jsx
#í›ˆë ¨ ì„¸íŠ¸ì˜ ì‚°ì ë„ë¥¼ ê·¸ë¦½ë‹ˆë‹¤
plt.scatter(train_input, train_target)
#15ì—ì„œ 50ê¹Œì§€ 1ì°¨ ë°©ì •ì‹ ê·¸ë˜í”„ë¥¼ ê·¸ë¦½ë‹ˆë‹¤
plt.plot([15, 50], [15*lr.coef_+lr.intercept_, 50*lr.coef_+lr.intercept_])
# 50cm ë†ì–´ ë°ì´í„°
plt.scatter(50, 1241.8, marker='^')
plt.xlabel('length')
plt.ylabel('weight')
plt.show()
```

![image.png](image%202.png)

ì„ í˜• íšŒê·€ ì•Œê³ ë¦¬ì¦˜ì´ ì´ ë°ì´í„°ì…‹ì—ì„œ ì°¾ì€ ìµœì ì˜ ì§ì„  â†’ 50cmì˜ ë†ì–´ ë¬´ê²Œë„ ì˜ˆì¸¡ ê°€ëŠ¥

```jsx
print(lr.score(train_input, train target)) # í›ˆë ¨ ì„¸íŠ¸
print(lr.score(test_input, test_target)) #í…ŒìŠ¤íŠ¸ ì„¸íŠ¸
```

- í›ˆë ¨ ì„¸íŠ¸ì™€ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì˜ ì ìˆ˜ ì°¨ì´ â†’ ì „ì²´ì ìœ¼ë¡œ ê³¼ì†Œì í•©
- ì´ ì§ì„ ëŒ€ë¡œ ì˜ˆì¸¡í•˜ë©´ ë†ì–´ì˜ ë¬´ê²Œê°€ 0g ì´í•˜ë¡œ ë‚˜ê°€ëŠ” ë¶ˆê°€ëŠ¥í•œ ì¼ ë°œìƒ

## ë‹¤í•­ íšŒê·€

- ìµœì ì˜ ì§ì„ ì„ ì°¾ê¸°ë³´ë‹¤ ìµœì ì˜ ê³¡ì„ ì„ ì°¾ê¸°ë¡œ ë³€ê²½
- 2ì°¨ ë°©ì •ì‹ì˜ ê·¸ë˜í”„ë¥¼ ê·¸ë¦¬ê¸° ìœ„í•´ ì´ë¥¼ ì œê³±í•œ í•­ì„ í›ˆë ¨ ì„¸íŠ¸ì— ì¶”ê°€

```jsx
train_poly = np.column_stack((train_input ** 2, train_input))
test_poly = np.column_stack((test_input ** 2, test_input))
print(train_poly.shape, test_poly.shape)
```

- ê¸¸ì´ë¥¼ ì œê³±í•˜ì—¬ ì™¼ìª½ ì—´ì— ì¶”ê°€í–ˆê¸° ë•Œë¬¸ì— í›ˆë ¨ ì„¸íŠ¸ì™€ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ëª¨ë‘ ì—´ì´ 2ê°œë¡œ ë³€ê²½

- train_polyë¥¼ ì‚¬ìš©í•´ ì„ í˜• íšŒê·€ ëª¨ë¸ì„ ë‹¤ì‹œ í›ˆë ¨
- 2ì°¨ ë°©ì •ì‹ ê·¸ë˜í”„ë¥¼ ì°¾ê¸° ìœ„í•´ í›ˆë ¨ ì„¸íŠ¸ì— ì œê³± í•­ì„ ì¶”ê°€í–ˆì§€ë§Œ, íƒ€ê¹ƒê°’ì€ ê·¸ëŒ€ë¡œ ì‚¬ìš©

```jsx
lr = LinearRegression()
lr.fit(train_poly, train_target)
print(lr.predict([[50**2, 50]]))
```

[1573.98423528] â†’ ì´ì „ ëª¨ë¸ë³´ë‹¤ ë” ë†’ì€ ì˜ˆì¸¡ê°’

```jsx
print (lr.coef_, lr.intercept_)
```

- ë¬´ê²Œ = 1.01 Ã— ê¸¸ì´ - 21.6 Ã— ê¸¸ì´ + 116.05
- ì´ ë‹¤í•­ì‹ì„ ì‚¬ìš©í•˜ì—¬ ì„ í˜• íšŒê·€ â†’ ë‹¤í•­ íšŒê·€

```jsx
#êµ¬ê°„ë³„ ì§ì„ ì„ ê·¸ë¦¬ê¸° ìœ„í•´ 15ì—ì„œ 49ê¹Œì§€ ì •ìˆ˜ ë°°ì—´ì„ ë§Œë“­ë‹ˆë‹¤.
point = np.arange(15, 50)
#í›ˆë ¨ ì„¸íŠ¸ì˜ ì‚°ì ë„ë¥¼ ê·¸ë¦½ë‹ˆë‹¤
plt.scatter(train_input, train_target)
#15ì—ì„œ 49ê¹Œì§€ 2ì°¨ ë°©ì •ì‹ ê·¸ë˜í”„ë¥¼ ê·¸ë¦½ë‹ˆë‹¤
plt.plot(point, 1.01*point**2 - 21.6*point + 116.05)
#50cm ë†ì–´ ë°ì´í„°
plt.scatter(50, 1574, marker='^')
plt.xlabel('length')
plt.ylabel('weight')
plt.show()
```

![image.png](image%203.png)

- ì‚°ì ë„ë¥¼ ê·¸ë¦° ê²°ê³¼ í›ˆë ¨ ì„¸íŠ¸ì˜ ê²½í–¥ì„ ì˜ ë”°ë¥´ê³  ìˆê³  ë¬´ê²Œë„ ì •ìƒì ìœ¼ë¡œ ë‚˜ì˜´

```jsx
print(lr.score(train_poly, train_target))
print(lr.score(test_poly, test_target))
```

 RÂ² ì ìˆ˜ë¥¼ í‰ê°€: í›ˆë ¨ ì„¸íŠ¸ì™€ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì— ëŒ€í•œ ì ìˆ˜ê°€ í¬ê²Œ ë†’ì•„ì§

# 3-3. íŠ¹ì„± ê³µí•™ê³¼ ê·œì œ

ì§€ê¸ˆê¹Œì§€ëŠ” ê¸¸ì´ì™€ ê¸¸ì´Â²ë§Œ ì‚¬ìš©í•œ 2ì°¨ ë‹¤í•­ íšŒê·€ë¥¼ ì¼ìŒ.

â†’ ê·¸ëŸ°ë° ì—¬ì „íˆ ê³¼ì†Œì í•©ì´ ë‚¨ì•„ìˆìŒ

â†’ ì•Œê³  ë³´ë‹ˆ **ë†’ì´ì™€ ë‘ê»˜ ë°ì´í„°ë„ ìˆì—ˆìŒ** â†’ íŠ¹ì„±ì´ ë¶€ì¡±í–ˆë˜ ê²ƒ

## ë‹¤ì¤‘ íšŒê·€

- ì—¬ëŸ¬ ê°œì˜ íŠ¹ì„±ì„ ì‚¬ìš©í•œ ì„ í˜• íšŒê·€
- **íŠ¹ì„± ìˆ˜ì™€ ì„ í˜• íšŒê·€ ëª¨ë¸ì˜ í˜•íƒœ**

| íŠ¹ì„± ìˆ˜ | ëª¨ë¸ì´ í•™ìŠµí•˜ëŠ” í˜•íƒœ | ìˆ˜í•™ì  í‘œí˜„ |
| --- | --- | --- |
| 1ê°œ | ì§ì„  (line) | ğ‘¦ = ğ‘ğ‘¥ + ğ‘ |
| 2ê°œ | í‰ë©´ (plane) | ğ‘¦ = ğ‘â‚ğ‘¥â‚ + ğ‘â‚‚ğ‘¥â‚‚ + ğ‘ |
| 3ê°œ ì´ìƒ | ì´ˆí‰ë©´ (hyperplane) | ğ‘¦ = ğ‘â‚ğ‘¥â‚ + ğ‘â‚‚ğ‘¥â‚‚ + ğ‘â‚ƒğ‘¥â‚ƒ + ... + ğ‘ |
- 3ì°¨ì› ì´ìƒì€ ì‹œê°í™”í•  ìˆ˜ ì—†ì§€ë§Œ, ìˆ˜í•™ì ìœ¼ë¡œëŠ” ì™„ì „íˆ ì²˜ë¦¬í•  ìˆ˜ ìˆìŒ
- ì„ í˜• íšŒê·€ëŠ” íŠ¹ì„±ì´ ë§ì•„ì§ˆìˆ˜ë¡ í›¨ì”¬ ë” ë³µì¡í•œ ê²½ê³„ë¥¼ í‘œí˜„í•  ìˆ˜ ìˆëŠ” ëª¨ë¸

**íŠ¹ì„± ê³µí•™**

- ë‹¨ìˆœí•œ `ê¸¸ì´`, `ë†’ì´`, `ë‘ê»˜` 3ê°œë§Œ ì“°ëŠ” ê²Œ ì•„ë‹ˆë¼

        ê·¸ ì œê³±ê°’, ê³±ì…ˆ ì¡°í•©(ìƒí˜¸ì‘ìš© í•­) ë“±ì„ ë§Œë“¤ì–´ íŠ¹ì„±ì„ í™•ì¥

- íŠ¹ì„±ì„ í™•ì¥í•˜ë©´, ì„ í˜• íšŒê·€ë¡œë„ ë¹„ì„ í˜•ì ì¸ ë³µì¡í•œ ê´€ê³„ë¥¼ í‘œí˜„ ê°€ëŠ¥
- ê³ ì°¨í•­ì„ ì¶”ê°€í•´ë„ ì—¬ì „íˆ ì„ í˜• íšŒê·€ëŠ” í•™ìŠµê³¼ í•´ì„ì´ ë¹ ë¥´ê³  ì•ˆì •ì 

```jsx
import pandas as pd 
df = pd.read_csv('https://bit.ly/perch_csv_data')
perch_full = df.to_numpy()
print(perch_full)

import numpy as np
perch_weight = np.array([
5.9, 32.0, 40.0, 51.5, 70.0, 100.0, 78.0, 80.0, 85.0, 85.0,
110.0, 115.0, 125.0, 130.0, 120.0, 120.0, 130.0, 135.0, 110.0,
130.0, 150.0, 145.0, 150.0, 170.0, 225.0, 145.0, 188.0, 180.0,
197.0, 218.0, 300.0, 260.0, 265.0, 250.0, 250.0, 300.0, 320.0,
514.0, 556.0, 840.0, 685.0, 700.0, 700.0, 690.0, 900.0, 650.0,
820.0, 850.0, 900.0, 1015.0, 820.0, 1100.0, 1000.0, 1100.0,
1000.0, 1000.0])

from sklearn.model_selection import train_test_split
train_input, test_input, train_target, test_target = train_test_split(
perch_full, perch_weight, random_state=42)
```

- ë°ì´í„° ì¤€ë¹„ í›„ perch_fullê³¼ perch_weightë¥¼ í›ˆë ¨ ì„¸íŠ¸ì™€ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ë‚˜ëˆ”

**ë³€í™˜ê¸°**: ì‚¬ì´í‚·ëŸ°ì—ì„œ  íŠ¹ì„±ì„ ë§Œë“¤ê±°ë‚˜ ì „ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ë‹¤ì–‘í•œ í´ë˜ìŠ¤ë¥¼ ì œê³µ

```jsx
from sklearn.preprocessing import PolynomialFeatures
poly = PolynomialFeatures()
poly.fit([[2, 3]])
print(poly.transform([[2, 3]]))
```

2ê°œì˜ íŠ¹ì„±(ì›ì†Œ)ì„ ê°€ì§„ ìƒ˜í”Œ [2, 3]ì´ 6ê°œì˜ íŠ¹ì„±ì„ ê°€ì§„ ìƒ˜í”Œ [1. 2.3.4.6.9.]ë¡œ ë³€í™˜ë¨

- ë¬´ê²Œ = ax ê¸¸ì´ + bx ë†’ì´ +cx ë‘ê»˜ + dx 1
- ê° íŠ¹ì„±ì„ ì œê³±í•œ í•­ì„ ì¶”ê°€í•˜ê³  íŠ¹ì„±ë¼ë¦¬ ì„œë¡œ ê³±í•œ í•­ì„ ì¶”ê°€

```jsx
poly = PolynomialFeatures(include_bias=False)
poly.fit([[2, 3]])
print(poly.transform([[2, 3]]))
```

ì ˆí¸ì„ ìœ„í•œ í•­ì´ ì œê±°ë˜ê³  íŠ¹ì„±ì˜ ì œê³±ê³¼ íŠ¹ì„±ë¼ë¦¬ ê³±í•œ í•­ë§Œ ì¶”ê°€ (1 ì œê±°)

```jsx
poly = PolynomialFeatures (include_bias=False)
poly.fit(train_input)
train_poly = poly.transform(train_input)
print(train_poly.shape)
```

```jsx
poly.get_feature_names_out()
```

9ê°œì˜ íŠ¹ì„± ë§Œë“¤ì–´ì§„ ê²ƒ í™•ì¸ â†’ 9ê°œì˜ íŠ¹ì„± ì¡°í•© í™•ì¸

['x0', 'x1', 'x2', 'x0^2', 'x0 x1', 'x0 x2', 'x1^2', 'x1 x2', 'x2^2']

```jsx
test_poly = poly.transform(test_input)
```

í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ë³€í™˜ ì™„ë£Œ

## ë‹¤ì¤‘ íšŒê·€ ëª¨ë¸ í›ˆë ¨

```jsx
from sklearn.linear_model import LinearRegression
lr = LinearRegression()
lr.fit(train_poly, train_target)

print(lr.score(train_poly, train_target))
```

0.9903183436982124 : ì•„ì£¼ ë†’ì€ ì ìˆ˜ â†’ íŠ¹ì„±ì´ ëŠ˜ì–´ë‚ ìˆ˜ë¡ ì„ í˜• íšŒê·€ì˜ ëŠ¥ë ¥ë„ ê°•í™”ë¨

```jsx
print(lr.score(test_poly, test_target))
```

í…ŒìŠ¤íŠ¸ ì ìˆ˜ëŠ” ë†’ì•„ì§€ì§€ëŠ” ì•Šì•˜ì§€ë§Œ ê³¼ì†Œì í•© ë¬¸ì œëŠ” ë°œìƒí•˜ì§€ ì•ŠìŒ

```jsx
poly = PolynomialFeatures (degree=5, include_bias=False)
poly.fit(train_input)
train_poly = poly.transform(train_input)
test_poly = poly.transform(test_input)
print(train_poly.shape)

lr.fit(train_poly, train_target)
print(lr.score(train_poly, train_target))
```

íŠ¹ì„±ì„ 55ê°œë¡œ ëŠ˜ë ¤ í›ˆë ¨ ê²°ê³¼ 0.9999â€¦ì˜ ì•„ì£¼ ë†’ì€ ê°’ì´ ë‚˜ì˜´

```jsx
print(lr.score(test_poly, test_target))
```

ê·¸ëŸ¬ë‚˜ í…ŒìŠ¤íŠ¸ ì ìˆ˜ëŠ” -144.40579436844948ë¡œ ì•„ì£¼ í° ìŒìˆ˜ê°€ ë¨

â†’ íŠ¹ì„±ì˜ ê°œìˆ˜ë¥¼ í¬ê²Œ ëŠ˜ë¦¬ë©´ ì„ í˜• ëª¨ë¸ì€ í›ˆë ¨ ì„¸íŠ¸ì— ëŒ€í•´ ê±°ì˜ ì™„ë²½í•˜ê²Œ í•™ìŠµí•  ìˆ˜ ìˆì§€ë§Œ 

    ì´ëŸ° ëª¨ë¸ì€ í›ˆë ¨ ì„¸íŠ¸ì— ë„ˆë¬´ ê³¼ëŒ€ì í•© ë˜ë¯€ë¡œ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œëŠ” íš¨ê³¼ê°€ ì—†ìŒ

## ê·œì œ

- ëª¨ë¸ì´ í›ˆë ¨ ì„¸íŠ¸ì— ê³¼ëŒ€ì í•©ë˜ì§€ ì•Šë„ë¡ ë§Œë“œëŠ” ê²ƒ
- ì„ í˜• íšŒê·€ ëª¨ë¸ì˜ ê²½ìš° íŠ¹ì„±ì— ê³±í•´ì§€ëŠ” ê³„ìˆ˜(ë˜ëŠ” ê¸°ìš¸ê¸°)ì˜ í¬ê¸°ë¥¼ ì‘ê²Œ ë§Œë“œëŠ” ì¼

55ê°œì˜ íŠ¹ì„±ìœ¼ë¡œ í›ˆë ¨í•œ ì„ í˜• íšŒê·€ ëª¨ë¸ì˜ ê³„ìˆ˜ë¥¼ ê·œì œ

â†’ í›ˆë ¨ ì„¸íŠ¸ì˜ ì ìˆ˜ë¥¼ ë‚®ì¶”ê³  ëŒ€ì‹  í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì˜ ì ìˆ˜ë¥¼ ë†’ì´ì

- ì¼ë°˜ì ìœ¼ë¡œ ì„ í˜• íšŒê·€ ëª¨ë¸ì— ê·œì œë¥¼ ì ìš©í•  ë•Œ ê³„ìˆ˜ ê°’ì˜ í¬ê¸°ê°€ ë§ì´ ë‹¤ë¥´ë©´ ê³µì •í•˜ê²Œ ì œì–´ë˜ì§€ ì•ŠìŒ
- ê·œì œë¥¼ ì ìš©í•˜ê¸° ì „ì— ë¨¼ì € ì •ê·œí™” í•„ìš”

```jsx
from sklearn.preprocessing import StandardScaler
ss = StandardScaler()
ss.fit(train_poly)
train_scaled = ss.transform(train_poly)
test_scaled = ss.transform(test_poly)
```

### ë¦¿ì§€ íšŒê·€

```jsx
from sklearn.linear_model import Ridge
ridge = Ridge()
ridge.fit(train_scaled, train_target)
print(ridge.score(train_scaled, train_target))
```

0.97906939â€¦ â†’ ì´ì „ ì ìˆ˜ë³´ë‹¤ ì•½ê°„ ë‚®ì•„ì§„ ì ìˆ˜

```jsx
 print(ridge.score(test_scaled, test_target))
```

0.9790693977615398 â†’ ì •ìƒìœ¼ë¡œ ëŒì•„ì˜¨ í…ŒìŠ¤íŠ¸ ì ìˆ˜

ë§ì€ íŠ¹ì„±ì„ ì‚¬ìš©í–ˆìŒì—ë„ ë¶ˆêµ¬í•˜ê³  í›ˆë ¨ ì„¸íŠ¸ì— ë„ˆë¬´ ê³¼ëŒ€ì í•©ë˜ì§€ ì•Šì•„ 

í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œë„ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì„

- alpha ë§¤ê°œë³€ìˆ˜ë¡œ ê·œì œì˜ ê°•ë„ë¥¼ ì¡°ì ˆ
- alpha ê°’ì´ í¬ë©´ ê·œì œ ê°•ë„ê°€ ì„¸ì§€ë¯€ë¡œ ê³„ìˆ˜ ê°’ì„ ë” ì¤„ì´ê³  ì¡°ê¸ˆ ë” ê³¼ì†Œì í•©ë˜ë„ë¡ ìœ ë„
- alpha ê°’ì´ ì‘ìœ¼ë©´ ê³„ìˆ˜ ê°ì†Œê°€ ì¤„ê³  ì„ í˜• íšŒê·€ ëª¨ë¸ê³¼ ìœ ì‚¬í•´ì§€ë¯€ë¡œ ê³¼ëŒ€ì í•©ë  ê°€ëŠ¥ì„±ì´ í¼

```jsx
import matplotlib.pyplot as plt
train_score = []
test_score = []

alpha_list = [0.001, 0.01, 0.1, 1, 10, 100]
for alpha in alpha_list:
    #ë¦¿ì§€ ëª¨ë¸ì„ ë§Œë“­ë‹ˆë‹¤
    ridge = Ridge(alpha=alpha)
    #ë¦¿ì§€ ëª¨ë¸ì„ í›ˆë ¨í•©ë‹ˆë‹¤.
    ridge.fit(train_scaled, train_target)
    #í›ˆë ¨ ì ìˆ˜ì™€ í…ŒìŠ¤íŠ¸ ì ìˆ˜ë¥¼ ì €ì¥í•©ë‹ˆë‹¤
    train_score.append(ridge.score(train_scaled, train_target))
    test_score.append(ridge.score(test_scaled, test_target))
```

- alpha ê°’ì„ 0.001ì—ì„œ 100ê¹Œì§€ 10ë°°ì”© ëŠ˜ë ¤ê°€ë©° ë¦¿ì§€ íšŒê·€ ëª¨ë¸ì„ í›ˆë ¨í•œ ë‹¤ìŒ

       í›ˆë ¨ ì„¸íŠ¸ì™€ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì˜ ì ìˆ˜ë¥¼ íŒŒì´ì¬ ë¦¬ìŠ¤íŠ¸ì— ì €ì¥

```jsx
plt.plot(np.log10(alpha_list), train_score)
plt.plot(np.log10(alpha_list), test_score)
plt.xlabel('alpha')
plt.ylabel('R^2')
plt.show()
```

![image.png](image%204.png)

- ìœ„: í›ˆë ¨ ì„¸íŠ¸ ê·¸ë˜í”„ / ì•„ë˜: í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ê·¸ë˜í”„
- ê·¸ë˜í”„ì˜ ì™¼ìª½: í›ˆë ¨ ì„¸íŠ¸ì—ëŠ” ì˜ ë§ê³  í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ëŠ” ê³¼ëŒ€ì í•©ì˜ ëª¨ìŠµ
- ê·¸ë˜í”„ì˜ ì˜¤ë¥¸ìª½: í›ˆë ¨ ì„¸íŠ¸ì™€ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì˜ ì ìˆ˜ê°€ ëª¨ë‘ ë‚®ì•„ì§€ëŠ” ê³¼ì†Œì í•©

```jsx
ridge = Ridge(alpha=0.1)
ridge.fit(train_scaled, train_target)
print(ridge.score(train_scaled, train_target))
print(ridge.score(test_scaled, test_target))
```

alpha ê°’ 0.1ë¡œ í›ˆë ¨ ê²°ê³¼ ì ìˆ˜ê°€ ëª¨ë‘ ë†’ê³  ê³¼ëŒ€ì í•© / ê³¼ì†Œì í•©ì´ ë°œìƒí•˜ì§€ ì•ŠìŒ

### ë¼ì˜ íšŒê·€

```jsx
from sklearn.linear_model import Lasso
lasso = Lasso()
lasso.fit(train_scaled, train_target)
print(lasso.score(train_scaled, train_target))

print(lasso.score(test_scaled, test_target))
```

í›ˆë ¨ ì ìˆ˜, í…ŒìŠ¤íŠ¸ ì ìˆ˜ ë‘˜ ë‹¤ ì¢‹ìŒ

```jsx
train_score = []
test_score = []
alpha_list = [0.001, 0.01, 0.1, 1, 10, 100]
for alpha in alpha_list:
#ë¼ì˜ ëª¨ë¸ì„ ë§Œë“­ë‹ˆë‹¤.
lasso = Lasso(alpha=alpha, max_iter=10000)
#ë¼ì˜ ëª¨ë¸ì„ í›ˆë ¨í•©ë‹ˆë‹¤.
lasso.fit(train_scaled, train_target)
# í›ˆë ¨ ì ìˆ˜ì™€ í…ŒìŠ¤íŠ¸ ì ìˆ˜ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.
train_score.append(lasso.score(train_scaled, train_target))
test_score.append(lasso.score(test_scaled, test_target))

```

alpha ê°’ì„ ë°”ê¾¸ì–´ ê°€ë©° ì ìˆ˜ ê³„ì‚°

```jsx
plt.plot(np.log10(alpha_list), train_score)
plt.plot(np.log10(alpha_list), test_score)
plt.xlabel('alpha')
plt.ylabel('R^2')
plt.show()
```

![image.png](image%205.png)

ì™¼ìª½ì€ ê³¼ëŒ€ì í•©, ì˜¤ë¥¸ìª½ìœ¼ë¡œ ê°ˆìˆ˜ë¡ í›ˆë ¨ ì„¸íŠ¸ì™€ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì˜ ì ìˆ˜ê°€ ì¢í˜€ì§€ê³  ìˆìŒ

ë¼ì˜ ëª¨ë¸ì—ì„œ ìµœì ì˜ alpha ê°’ì€ 1, ì¦‰ 10*1=10

```jsx
 lasso = Lasso(alpha=10)
lasso.fit(train_scaled, train_target)
print(lasso.score(train_scaled, train_target))
print(lasso.score(test_scaled, test_target))
```

ë¼ì˜ ëª¨ë¸ì´ ê³¼ëŒ€ì í•©ì„ ì˜ ì–µì œí•˜ê³  í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì˜ ì„±ëŠ¥ì„ í¬ê²Œ ë†’ì¸ ê²°ê³¼

```jsx
print(np.sum(lasso.coef_ == 0))
```

40ê°œì˜ ê°’ì´ 0ì´ ë¨ â†’ 55ê°œì˜ íŠ¹ì„±ì„ ëª¨ë¸ì— ì£¼ì…í–ˆì§€ë§Œ ë¼ì˜ ëª¨ë¸ì´ ì‚¬ìš©í•œ íŠ¹ì„±ì€ 15ê°œ

â†’ ë¼ì˜ ëª¨ë¸ì„ ìœ ìš©í•œ íŠ¹ì„±ì„ ê³¨ë¼ë‚´ëŠ” ìš©ë„ë¡œë„ ì‚¬ìš© ê°€ëŠ¥
